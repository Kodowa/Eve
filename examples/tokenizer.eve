This is a tokenizer for Eve's current syntax, which takes code from a #code object, breaks
it into characters and then aggregates those into tokens of various types. Before we do
that, we'll first create some #char-type and #keyword objects to match against

  type = "whitespace"
  maintain
    [#char-type type char: " "] [#char-type type char: "\n"] [#char-type type char: "\t"]

numeric character types
  type = "numeric"
  maintain
    [#char-type type char: "0"] [#char-type type char: "1"] [#char-type type char: "2"]
    [#char-type type char: "3"] [#char-type type char: "4"] [#char-type type char: "5"]
    [#char-type type char: "6"] [#char-type type char: "7"] [#char-type type char: "8"]
    [#char-type type char: "9"] [#char-type type char: "."]

special character types
  type = "special"
  maintain
    [#char-type type char: "@"] [#char-type type char: "("] [#char-type type char: ":"]
    [#char-type type char: "#"] [#char-type type char: ")"] [#char-type type char: "⦑"]
    [#char-type type char: "."] [#char-type type char: "["] [#char-type type char: "⦒"]
    [#char-type type char: ","] [#char-type type char: "]"] [#char-type type char: "\""]

keywords
  maintain
    [#keyword string: "update"] [#keyword string: "if"] [#keyword string: "then"]
    [#keyword string: "else"] [#keyword string: "end"] [#keyword string: "or"]
    [#keyword string: "not"] [#keyword string: "none"] [#keyword string: "given"]
    [#keyword string: "="] [#keyword #inequality string: "!="]
    [#keyword #inequality string: ">"] [#keyword #inequality string: "<"]
    [#keyword #inequality string: ">="] [#keyword #inequality string: "<="]
    [#keyword #infix string: "+"] [#keyword #infix string: "-"]
    [#keyword #infix string: "*"] [#keyword #infix string: "/"]
    [#keyword #mutate string: ":="] [#keyword #mutate string: "+="]
    [#keyword #mutate string: "-="]

Now we'll split our code into characters and determine the rough type of character
we're dealing with by matching with the #char-type objects we added

  block = [#code code]
  [#split text: code, by: "", token, index]
  type = if [#char-type type char: token] then type
         else "identifier"
  maintain
    block.char += [#char char: token, index, type, block]

To start making tokens, we'll look at characters that immediately follow
a whitespace character. Assuming we're not in some mode (like parsing a string)
then this is a new token

  prev = [#char block, type: "whitespace", not(mode)]
  char = [#char block index: prev.index + 1, type]
  type != "whitespace"
  maintain
    token = [#token block char, start: char.index]
    char := [token]

A character that follows a char that already has a token and is of a different type
also creates a new token

  prev = [#char block not(mode) token]
  char = [#char block, index: prev.index + 1, type != prev.type]
  char.type != "whitespace"
  maintain
    token = [#token block char, start: char.index]
    char := [token]

if we're not in a mode and the previous char is of the same type and has a token
then we'll add this character to that token. We also want to handle the case
where the previous char is an identifier and the next is numeric so that identifiers
can have numbers in them.

  char = [#char block, index, type]
  prev = [#char block index: index - 1, token, not(mode)]
  prev = if prev.type = type then prev
         else if prev.type = "identifier"
                 type = "numeric" then prev
  maintain
    token += [char]
    char := [token]

uuids are defined by starting with ⦑ and ending with ⦒. To handle that we'll put
the parser into uuid mode so that we know to just eat all the characters until
we get to the end delimiter

  [#char char: "⦑" block, index, not(mode)]
  next = [#char block index: index + 1]
  maintain
    token = [#token block char: next, start: next.index, type: "uuid"]
    next := [token mode: "uuid"]

Now we need handle adding chars to the uuid token so long as we're not at 
the closing ⦒. If we are, we just don't set the mode.

  prev = [#char block, index, mode: "uuid" token]
  next = [#char block, index: index + 1, char != "⦒"]
  maintain
    token.char += next
    next := [token mode: "uuid"]

strings are similar to uuids in that they are delimited, the only problem
is that we need to worry about escaped quotes in them. To start we just look
for any quote character that isn't currently in a mode and we say that the
next char is part of the token.

  [#char char: "\"" block, index, not(mode)]
  next = [#char block index: index + 1]
  maintain
    token = [#token block char: next, start: next.index, type: "string"]
    next := [token mode: "string"]

Now we consume characters if the previous char is in string mode and either
the current character is not a quote or the previous character is a \

  prev = [#char block, index, mode: "string", token]
  next = [#char block, index: index + 1]
  next = if next.char != "\"" then next
         else if prev.char = "\\" then next
  maintain
    token.char += next
    next := [token mode: "string"]

The last special case we need to deal with is for doc strings (any text at the top level),
which we identify by looking for new line characters where the next char is not whitespace
or we're at index 0 and it's not whitespace. 

  next = if [#char char: "\n" block, index, not(mode)]
            char = [#char block index: index + 1, type != "whitespace"] then char
         else if char = [#char block, index: 0, not(mode), type != "whitespace"] then char
  maintain
    token = [#token block char: next, start: next.index, type: "doc"]
    next := [token mode: "doc"]

We consume doc mode characters until we hit a new line

  prev = [#char block, index, mode: "doc" token]
  next = [#char block, index: index + 1, char != "\n"]
  maintain
    token.char += next
    next := [token mode: "doc"]

Once we've gotten all the chars for a token we need to condense that into
a single value, a token type, and a length. By default, the token type
is just the type of the first character.

  token = [#token block char start not(type)]
  [#char block token, index: start, type]
  maintain
    token.type := type
    token.value := concat(char.char, char.index given char)
    token.length := count(given char)

We also need to check if any of the tokens are keywords and associate
the keyword with them if they are.

  token = [#token value]
  keyword = [#keyword string: value]
  maintain
    token.keyword := keyword
    token.type := "keyword"

Let's also give an index to all of the tokens so we can later
parse them in order
  
  token = [#token block start]
  index = index(given start increasing per block)
  maintain
    token.index := index

